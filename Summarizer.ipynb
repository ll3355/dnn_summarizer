{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING/PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#Function that removes stop-words, punctuations, number and lower-casing\n",
    "def extract_sentence(sent):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    sent = sent.lower() #Lower casing\n",
    "    sent = re.sub(re.compile(r'<.*?>'),'', sent)\n",
    "    tokens = [w for w in sent.split() if not w in stop_words] #remove stop-words\n",
    "    sent = (\" \".join(tokens)).strip()\n",
    "    \n",
    "    sent = re.sub(r'\\d','', sent) #remove number\n",
    "    sent = re.sub(r'[^\\w\\s]','',sent) #remove punctuation\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('newdataset1.csv')\n",
    "\n",
    "newreview = df['review']\n",
    "newsummary = df['summary']\n",
    "\n",
    "clean_review = []\n",
    "clean_summary = []\n",
    "for i in range(len(newreview)):\n",
    "    clean_review.append(extract_sentence(newreview[i]))\n",
    "    clean_summary.append(extract_sentence(newsummary[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = pd.DataFrame(clean_review, columns=['review'])\n",
    "newdata['summary'] = clean_summary\n",
    "newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT TRAIN AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split train and test\n",
    "train, test = train_test_split(newdata, test_size = 0.2)\n",
    "train.to_csv('train.csv', index=False)\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WORDS TO NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, TabularDataset, BucketIterator, BPTTIterator, Iterator\n",
    "import spacy\n",
    "import torch\n",
    "\n",
    "spacy = spacy.load('en')\n",
    "\n",
    "def tokenize(text):\n",
    "    return [tok.text for tok in spacy.tokenizer(text)]\n",
    "\n",
    "review = Field(\n",
    "    sequential=True, use_vocab = True,tokenize=tokenize,lower=True\n",
    ")\n",
    "summary = Field(\n",
    "    sequential=True, use_vocab = True,tokenize=tokenize,\n",
    "    lower=True,init_token = '<sos>',eos_token = '<eos>'\n",
    ")\n",
    "\n",
    "field = [('review',review),('summary', summary)]\n",
    "\n",
    "train_x,test_x = TabularDataset.splits(\n",
    "    path='', skip_header=True, train = 'train.csv', test = 'test.csv',\n",
    "    format = 'csv', fields= field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "review.build_vocab(train_x, max_size=10000, min_freq=2, vectors='glove.6B.100d')\n",
    "summary.build_vocab(train_x, max_size=10000, min_freq=2, vectors='glove.6B.100d')\n",
    "\n",
    "train_iter, test_iter = BucketIterator.splits((train_x, test_x), batch_size = 10, \n",
    "                                              sort_key=lambda x:len(x.review), sort_within_batch = True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import optim\n",
    "import random\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.hid_size = hidden_size #hidden_size should be the same as decor\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.rnn = nn.LSTM(emb_size, hidden_size, n_layers, dropout = dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, output_size, n_layers, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_size = output_size\n",
    "        self.hid_size = hidden_size #hidden_size should be the same as encoder\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.rnn = nn.LSTM(emb_size, hidden_size, n_layers, dropout = dropout)\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden, cell):\n",
    "        \n",
    "        x = x.unsqueeze(0) #making x: (1,N)\n",
    "    \n",
    "        embedded = self.dropout(self.embedding(x))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "        prediction = self.fc_out(output)\n",
    "        \n",
    "        prediction = prediction.squeeze(0)\n",
    "\n",
    "        return prediction, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        \n",
    "    def forward(self, review, summary, teacher_forcing_ratio = 0.5):\n",
    "\n",
    "        batch_size = summary.shape[1]\n",
    "        summary_len = summary.shape[0]\n",
    "        summary_vocab_size = self.decoder.output_size #len(summary.vocab)\n",
    "\n",
    "        outputs = torch.zeros(summary_len, batch_size, summary_vocab_size)\n",
    "        \n",
    "        hidden, cell = self.encoder(review)\n",
    "        \n",
    "        #start token <sos>\n",
    "        x = summary[0,:]\n",
    "        \n",
    "        for t in range(1, summary_len):\n",
    "            output, hidden, cell = self.decoder(x, hidden, cell)\n",
    "            \n",
    "            outputs[t] = output #store outputs of decoder\n",
    "\n",
    "            pred = output.argmax(1) #best guess\n",
    "            \n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                x = summary[t] \n",
    "            else:\n",
    "                x = pred\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training function\n",
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        review = batch.review\n",
    "        summary = batch.summary\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(review, summary)\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        summary = summary[1:].view(-1)\n",
    "\n",
    "        \n",
    "        loss = criterion(output, summary)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluation function\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            review = batch.review\n",
    "            summary = batch.summary\n",
    "\n",
    "            output = model(review, summary, 0) \n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            summary = summary[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, summary)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to output summary\n",
    "def summarize(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            review = batch.review\n",
    "            summary = batch.summary\n",
    "\n",
    "            output = model(review, summary, 0) \n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            summary = summary[1:].view(-1)\n",
    "\n",
    "            loss = criterion(output, summary)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 0.001\n",
    "vocab_size_encoder = len(review.vocab)\n",
    "vocab_size_decoder = len(review.vocab)\n",
    "output_size = len(summary.vocab)\n",
    "encoder_embedding_size = 300\n",
    "decoder_embedding_size = 300\n",
    "hidden_size = 1024\n",
    "num_layers = 2 #2 or 4 or more\n",
    "dropout = 0.5\n",
    "\n",
    "encoder = Encoder(vocab_size_encoder, encoder_embedding_size, hidden_size, num_layers, dropout)\n",
    "decoder = Decoder(vocab_size_decoder, decoder_embedding_size, hidden_size, output_size,\n",
    "                      num_layers, dropout)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_idx = review.vocab.stoi['<pad>']\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "#timer function to keep track of duration of each epoch\n",
    "def timer(tic, toc):\n",
    "    time = toc - tic\n",
    "    mins = int(time / 60)\n",
    "    sec = int(time - (mins * 60))\n",
    "    return mins, sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(6008, 300)\n",
       "    (rnn): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (embedding): Embedding(6008, 300)\n",
       "    (rnn): LSTM(300, 1024, num_layers=2, dropout=0.5)\n",
       "    (fc_out): Linear(in_features=1024, out_features=704, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize the weight\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, -0.08, 0.08)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Time: 3m 38s\n",
      "\tTrain Loss: 7.051\n",
      "Epoch: 2 | Time: 2m 33s\n",
      "\tTrain Loss: 5.218\n",
      "Epoch: 3 | Time: 2m 34s\n",
      "\tTrain Loss: 4.578\n",
      "Epoch: 4 | Time: 2m 34s\n",
      "\tTrain Loss: 4.333\n",
      "Epoch: 5 | Time: 2m 33s\n",
      "\tTrain Loss: 4.260\n",
      "Epoch: 6 | Time: 2m 40s\n",
      "\tTrain Loss: 4.226\n",
      "Epoch: 7 | Time: 2m 40s\n",
      "\tTrain Loss: 4.185\n",
      "Epoch: 8 | Time: 2m 33s\n",
      "\tTrain Loss: 4.163\n",
      "Epoch: 9 | Time: 2m 34s\n",
      "\tTrain Loss: 4.152\n",
      "Epoch: 10 | Time: 2m 35s\n",
      "\tTrain Loss: 4.130\n",
      "Epoch: 11 | Time: 2m 41s\n",
      "\tTrain Loss: 4.112\n",
      "Epoch: 12 | Time: 2m 43s\n",
      "\tTrain Loss: 4.108\n",
      "Epoch: 13 | Time: 2m 44s\n",
      "\tTrain Loss: 4.087\n",
      "Epoch: 14 | Time: 2m 48s\n",
      "\tTrain Loss: 4.068\n",
      "Epoch: 15 | Time: 2m 43s\n",
      "\tTrain Loss: 4.057\n",
      "Epoch: 16 | Time: 2m 45s\n",
      "\tTrain Loss: 4.042\n",
      "Epoch: 17 | Time: 2m 52s\n",
      "\tTrain Loss: 4.032\n",
      "Epoch: 18 | Time: 2m 46s\n",
      "\tTrain Loss: 4.018\n",
      "Epoch: 19 | Time: 2m 52s\n",
      "\tTrain Loss: 4.006\n",
      "Epoch: 20 | Time: 2m 51s\n",
      "\tTrain Loss: 3.990\n"
     ]
    }
   ],
   "source": [
    "#training using train.csv\n",
    "\n",
    "num_epochs = 20\n",
    "CLIP = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    tic = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iter, optimizer, criterion, CLIP)\n",
    "    \n",
    "    toc = time.time()\n",
    "    \n",
    "    mins, sec = timer(tic, toc)\n",
    "    \n",
    "\n",
    "    torch.save(model.state_dict(), 'modelseq2seq.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1} | Time: {mins}m {sec}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Loss: 3.447\n"
     ]
    }
   ],
   "source": [
    "#evaluation using test.csv\n",
    "model.load_state_dict(torch.load('modelseq2seq.pt'))\n",
    "test_loss = evaluate(model, test_iter, criterion)\n",
    "\n",
    "print(f' Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to convert output of model into words\n",
    "def tensor_to_sentence(output):\n",
    "    output = torch.round(output)\n",
    "    trans_sent = []\n",
    "    xsumm = []\n",
    "\n",
    "    for i in range(len(output)):\n",
    "        xsumm.append(int(output[i]))\n",
    "\n",
    "    for i in xsumm:\n",
    "        convert = review.vocab.itos[i]\n",
    "        trans_sent.append(convert)\n",
    "        \n",
    "    trans_sent = \" \".join(trans_sent)\n",
    "    return trans_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie youthful yj zombi film one one film film zombi film zombi zombi zombi zeffirelli zhukov zeffirelli zeffirelli zhukov zhukov film zhukov film zhukov film zhukov zhukov zealots zhukov zealots zhukov zhukov zeffirelli zeffirelli zhukov zealots film zeffirelli zeffirelli   zeffirelli zeffirelli zealots zealots zeffirelli zhukov   zealots zhukov zealots zeffirelli zealots zeffirelli zeffirelli   zealots zealots zhukov zeffirelli zeffirelli zealots zeffirelli zeffirelli zeffirelli zeffirelli zeffirelli zealots zeffirelli zeffirelli zeffirelli zhukov zealots zealots zeffirelli zeffirelli zeffirelli zeffirelli film zeffirelli zealots zhukov zeffirelli zeffirelli zeffirelli zeffirelli zeffirelli zeffirelli zealots zealots zeffirelli zealots zeffirelli zeffirelli zeffirelli zealots zeffirelli zealots zaljko zombi zealots zeffirelli zealots zeffirelli zaljko zealots zealots film zeffirelli film zealots zeffirelli zealots zeffirelli zealots zealots zealots zealots zealots zaljko zeffirelli zaljko zeffirelli zeffirelli zeffirelli zaljko zeffirelli zaljko zealots zealots zealots zealots zealots zeffirelli zaljko zealots zeffirelli zealots zealots zaljko zealots zealots zhukov zaljko zeffirelli zealots zealots zealots zhukov zealots zealots zeffirelli zeffirelli zealots zealots zealots zealots zealots zealots zeffirelli zeffirelli zeffirelli zaljko zealots zealots zhukov zealots zealots zealots zealots zeffirelli <pad> film zealots zeffirelli zealots zealots zeffirelli zeffirelli film zeffirelli film zaljko zeffirelli zaljko zaljko zealots zaljko zeffirelli zealots zeffirelli zeffirelli zealots zealots zeffirelli zaljko zealots zealots zealots zealots zaljko zaljko zaljko zaljko zealots zealots zealots zeffirelli zealots zealots zealots zaljko zealots zealots zeffirelli zaljko zealots zealots zealots zaljko zealots zaljko zaljko zealots zeffirelli zealots zaljko zealots zaljko zeffirelli film zaljko zeffirelli zealots film zealots zhukov zealots z zeffirelli zaljko zealots zeffirelli zealots zealots zealots zeffirelli zeffirelli zealots zealots zaljko zeffirelli zealots zealots zealots zeffirelli zealots zealots film zealots zaljko zaljko zeffirelli zeffirelli zaljko zealots zealots z zealots zealots   zealots zealots zealots zealots zaljko zealots zealots zealots zeffirelli zealots zaljko zaljko zealots zealots zealots zealots zealots zeffirelli zealots zealots zaljko film zaljko zealots zealots film zeffirelli zeffirelli zaljko zaljko zealots <pad> z zealots zaljko zealots zaljko zaljko zealots zaljko zaljko film zeffirelli zealots zaljko zealots zealots zeffirelli zaljko zaljko zealots zaljko zaljko film zaljko zealots zealots zeffirelli zeffirelli zealots zealots film zealots z zaljko z zealots zaljko zeffirelli z zealots zealots zealots z zealots zealots zaljko z zaljko zealots zaljko zealots zealots zaljko zealots zealots film zaljko zealots zealots z zaljko zealots zaljko zealots zealots zaljko zealots zaljko zeffirelli zaljko zealots zaljko zaljko zeffirelli zaljko zaljko zaljko zealots zealots zaljko zealots zealots zealots z z zaljko zaljko zaljko zaljko zaljko zaljko zealots zealots zaljko zealots zaljko zealots zealots zaljko z zaljko zaljko zaljko zealots zealots zealots zaljko zealots zaljko zaljko zeffirelli zaljko zealots zealots zeffirelli zaljko zealots zeffirelli zaljko zealots zeffirelli zaljko zealots zaljko zealots zealots zealots zealots zaljko z zaljko zealots zaljko zaljko zeffirelli zealots zealots zaljko zaljko zealots zealots zaljko zealots zaljko zaljko zaljko zaljko zaljko zeffirelli zaljko zaljko z zaljko zealots zaljko zaljko zaljko zealots zeffirelli zaljko zealots zaljko zaljko zaljko zaljko zealots film zealots zhukov zealots zealots zaljko zaljko zealots zealots zealots zaljko zealots zaljko zaljko zealots zaljko zaljko zaljko zaljko     zealots zaljko zealots zealots zealots zaljko zealots zealots zaljko zealots film zaljko zaljko zaljko zaljko z zaljko zaljko zaljko zaljko zealots zaljko zeffirelli zaljko zealots film zealots zaljko zealots zaljko zealots zaljko zaljko zaljko zeffirelli zaljko zealots zaljko zaljko zealots zaljko zaljko zealots zealots zaljko zealots zealots zaljko zealots zaljko zealots zaljko zaljko zaljko z film zaljko zealots zaljko zaljko zealots zaljko zeffirelli zeffirelli zaljko zaljko zeffirelli zealots zealots zealots zealots zealots zealots zaljko zaljko zeffirelli zeffirelli zaljko zealots zeffirelli zaljko zaljko zealots zealots zealots zealots film zaljko zeffirelli z zaljko z film film zealots zealots zaljko film zaljko zaljko zaljko zealots z zealots zaljko zaljko zaljko z zaljko zaljko z zaljko zaljko zaljko zealots zealots zaljko z zealots zealots zaljko zaljko zaljko zaljko zaljko zealots zealots zealots zaljko zaljko zaljko zealots zaljko zaljko zaljko zealots zaljko zaljko zealots zealots zealots zaljko zealots zaljko zaljko zaljko zeffirelli zaljko zaljko zaljko z zealots zealots zaljko zealots zealots zealots zealots z zaljko zaljko zealots zealots z z zealots zealots zealots zaljko zaljko zaljko zealots zealots zaljko zealots zealots zealots zaljko zaljko film zealots zaljko zeffirelli zealots zealots zaljko zealots zaljko zealots zaljko zealots zealots zaljko zaljko zaljko zaljko zealots zealots zaljko zaljko zealots zaljko zaljko zealots zaljko film zealots zaljko zaljko zealots zealots zealots zaljko zealots zealots zaljko\n"
     ]
    }
   ],
   "source": [
    "#summary test\n",
    "model.load_state_dict(torch.load('modelseq2seq.pt'))\n",
    "output = summarize(model, test_iter, criterion)\n",
    "\n",
    "output_sentence = tensor_to_sentence(output[0])\n",
    "print(output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
